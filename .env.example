# LLM Provider Configuration
# Choose one: groq, openai, anthropic, ollama
LLM_PROVIDER=groq

# Groq API Key (FREE - Get from https://console.groq.com/)
GROQ_API_KEY=your_groq_api_key_here

# OpenAI API Key (Optional - only if you have subscription)
# OPENAI_API_KEY=your_openai_api_key_here

# Anthropic API Key (Optional - only if you have subscription)
# ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Model Configuration
# For Groq: llama-3.1-70b-versatile, llama-3.1-8b-instant, mixtral-8x7b-32768
# For OpenAI: gpt-4-turbo-preview, gpt-3.5-turbo
# For Ollama: llama3.1:8b, llama3.2:3b
LLM_MODEL=llama-3.1-70b-versatile

# Embedding Provider (local = free, no API key needed)
EMBEDDING_PROVIDER=local
# EMBEDDING_MODEL=text-embedding-3-small  # Only if using OpenAI embeddings

# Vector Database Configuration
CHROMA_PERSIST_DIR=./data/chroma_db

# Application Settings
MAX_QUESTIONS_PER_SESSION=10
ANSWER_MAX_TOKENS=500
TEMPERATURE=0.7
